# üï∑Ô∏è Scraper de Noticias Multi-Fuente

Sistema completo de scraping para extraer noticias de 11 fuentes especializadas en tecnolog√≠a, IA y actualidad.

## üì∞ Fuentes Configuradas

1. **Supply Chain Digital** - https://supplychaindigital.com/
2. **UNESCO** - https://www.unesco.org/en
3. **Infobae** - https://www.infobae.com/
4. **Xataka** - https://www.xataka.com/
5. **Genbeta** - https://www.genbeta.com/
6. **Hipertextual** - https://hipertextual.com/
7. **TechCrunch** - https://techcrunch.com/
8. **The Verge** - https://www.theverge.com/
9. **OpenAI News** - https://openai.com/es-419/news/
10. **Anthropic Engineering** - https://www.anthropic.com/engineering
11. **DeepMind Blog** - https://deepmind.google/blog/

## üöÄ Instalaci√≥n R√°pida

```bash
# 1. Navegar a la carpeta
cd "c:\Users\PASANTE 2\Documents\scraper"

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar el scraper
python ejecutar_busquedas.py
```

## üí° Modos de Uso

### Opci√≥n 1: Ejecutar Todas las B√∫squedas Predefinidas

```bash
python ejecutar_busquedas.py
# Seleccionar opci√≥n 1
```

**B√∫squedas incluidas:**
- ‚úÖ Inteligencia Artificial
- ‚úÖ China y la IA
- ‚úÖ Blockchain y Criptomonedas
- ‚úÖ Rob√≥tica y Automatizaci√≥n
- ‚úÖ Cambio Clim√°tico y Sostenibilidad

**Resultado:** Genera archivos JSON individuales para cada b√∫squeda + un archivo consolidado.

### Opci√≥n 2: B√∫squeda Personalizada

```bash
python ejecutar_busquedas.py
# Seleccionar opci√≥n 2
# Ingresar tema y palabras clave
```

### Opci√≥n 3: Solo IA

```bash
python ejecutar_busquedas.py
# Seleccionar opci√≥n 3
```

### Opci√≥n 4: Solo China y IA

```bash
python ejecutar_busquedas.py
# Seleccionar opci√≥n 4
```

## üîß Uso Program√°tico

### Ejemplo B√°sico

```python
from news_sources_scraper import NewsSourcesScraper

# Crear scraper
scraper = NewsSourcesScraper()

# Definir palabras clave
keywords = ['IA', 'inteligencia artificial', 'AI', 'ChatGPT']

# Ejecutar b√∫squeda
resultado = scraper.generate_search_result(
    search_query="Inteligencia Artificial",
    keywords=keywords
)

# Guardar resultados
scraper.save_results(resultado, 'mi_busqueda.json')

# Acceder a los hallazgos
print(f"Total de art√≠culos: {resultado['total_hallazgos']}")
for hallazgo in resultado['hallazgos']:
    print(f"- {hallazgo['titulo']}")
    print(f"  Fuente: {hallazgo['fuente']}")
    print(f"  URL: {hallazgo['url']}")
```

### Ejemplo Avanzado - Scraping de Fuente Individual

```python
from news_sources_scraper import NewsSourcesScraper

scraper = NewsSourcesScraper()

# Scrapear solo TechCrunch
resultado = scraper.scrape_source(
    url="https://techcrunch.com/",
    keywords=['startup', 'funding', 'AI']
)

print(f"Art√≠culos encontrados: {resultado['articulos_encontrados']}")

for articulo in resultado['articulos']:
    print(f"\n{articulo['titulo']}")
    print(f"URL: {articulo['url']}")
    print(f"Descripci√≥n: {articulo['descripcion']}")
```

### Ejemplo - Scraping de Todas las Fuentes sin Filtro

```python
from news_sources_scraper import NewsSourcesScraper

scraper = NewsSourcesScraper()

# Scrapear todas las fuentes sin filtrar por keywords
resultados = scraper.scrape_all_sources(
    keywords=None,  # Sin filtro
    delay=2.0  # 2 segundos entre requests
)

# Procesar resultados
for fuente in resultados:
    print(f"\n{fuente['nombre_fuente']}")
    print(f"  Estado: {fuente['estado']}")
    print(f"  Art√≠culos: {fuente['articulos_encontrados']}")
```

## üìä Estructura del JSON Generado

```json
{
  "busqueda_realizada": "Inteligencia Artificial",
  "timestamp": "2025-12-22T09:38:00.000000",
  "total_fuentes_consultadas": 11,
  "fuentes_exitosas": 10,
  "total_hallazgos": 45,
  "hallazgos": [
    {
      "fuente": "TechCrunch",
      "url_fuente": "https://techcrunch.com/",
      "titulo": "OpenAI lanza nuevo modelo GPT-5",
      "url": "https://techcrunch.com/2025/...",
      "descripcion": "OpenAI ha anunciado...",
      "imagen": "https://...",
      "fecha": "2025-12-22",
      "relevancia": 5
    }
  ],
  "detalle_por_fuente": [
    {
      "fuente": "https://techcrunch.com/",
      "nombre_fuente": "Techcrunch",
      "estado": "completado",
      "articulos_encontrados": 8,
      "articulos": [...]
    }
  ]
}
```

### Campos Explicados

| Campo | Descripci√≥n |
|-------|-------------|
| `busqueda_realizada` | Tema de la b√∫squeda |
| `timestamp` | Fecha y hora de la b√∫squeda |
| `total_fuentes_consultadas` | N√∫mero de fuentes intentadas |
| `fuentes_exitosas` | Fuentes que respondieron exitosamente |
| `total_hallazgos` | Art√≠culos encontrados que coinciden con keywords |
| `hallazgos` | Array con todos los art√≠culos relevantes |
| `relevancia` | Puntuaci√≥n basada en coincidencia de keywords |
| `detalle_por_fuente` | Informaci√≥n detallada de cada fuente |

## üìÅ Archivos Generados

Despu√©s de ejecutar el scraper, se generan:

### B√∫squeda Individual
- `busqueda_inteligencia_artificial.json`
- `busqueda_china_y_la_ia.json`
- `busqueda_blockchain_y_criptomonedas.json`
- etc.

### Archivo Consolidado
- `todas_las_busquedas.json` - Contiene todas las b√∫squedas en un solo archivo

### B√∫squeda Personalizada
- `busqueda_personalizada_[tema].json`

## ‚öôÔ∏è Configuraci√≥n

### Modificar Fuentes

Edita el archivo `news_sources_scraper.py`:

```python
class NewsSourcesScraper:
    SOURCES = [
        "https://tu-nueva-fuente.com/",
        # ... m√°s fuentes
    ]
```

### Ajustar Delay Entre Requests

```python
# En ejecutar_busquedas.py o en uso program√°tico
resultados = scraper.scrape_all_sources(
    keywords=keywords,
    delay=3.0  # Aumentar a 3 segundos
)
```

### Personalizar Keywords para B√∫squeda

Edita el archivo `ejecutar_busquedas.py`:

```python
BUSQUEDAS = [
    {
        'nombre': 'Tu Tema',
        'keywords': [
            'keyword1', 'keyword2', 'keyword3'
        ]
    }
]
```

## üéØ Caracter√≠sticas Principales

‚úÖ **Scraping Inteligente**
- Detecci√≥n autom√°tica de art√≠culos con selectores gen√©ricos
- Extracci√≥n de t√≠tulo, descripci√≥n, imagen, fecha y URL
- Compatible con m√∫ltiples estructuras HTML

‚úÖ **Filtrado por Relevancia**
- Sistema de puntuaci√≥n basado en keywords
- Ordenamiento autom√°tico por relevancia
- Filtrado flexible con m√∫ltiples palabras clave

‚úÖ **Manejo Robusto de Errores**
- Timeouts configurables
- Continuaci√≥n autom√°tica ante fallos
- Registro de estado por fuente

‚úÖ **Exportaci√≥n Estructurada**
- Formato JSON estandarizado
- Archivos individuales y consolidados
- Metadatos completos de cada b√∫squeda

## üîç Casos de Uso

### 1. Monitoreo de Noticias de IA
```bash
python ejecutar_busquedas.py
# Opci√≥n 3 - Solo Inteligencia Artificial
```

### 2. An√°lisis de Competencia (China)
```bash
python ejecutar_busquedas.py
# Opci√≥n 4 - China y la IA
```

### 3. Investigaci√≥n de Tendencias
```bash
python ejecutar_busquedas.py
# Opci√≥n 2 - B√∫squeda personalizada
# Ej: "Quantum Computing", keywords: quantum, qubit, etc.
```

### 4. Agregaci√≥n de Noticias Diarias
```python
# Script automatizado
from news_sources_scraper import NewsSourcesScraper
from datetime import datetime

scraper = NewsSourcesScraper()
resultado = scraper.generate_search_result(
    search_query=f"Noticias Diarias - {datetime.now().date()}",
    keywords=None  # Sin filtro, todas las noticias
)

scraper.save_results(resultado, f"noticias_{datetime.now().date()}.json")
```

## üìà Mejores Pr√°cticas

1. **Respetar Rate Limits**
   - Usa delays de al menos 1-2 segundos entre requests
   - No ejecutes el script con demasiada frecuencia

2. **Keywords Efectivas**
   - Usa variaciones del t√©rmino (ej: "IA", "AI", "inteligencia artificial")
   - Incluye t√©rminos en ingl√©s y espa√±ol
   - A√±ade nombres de empresas/productos relacionados

3. **Verificaci√≥n de Resultados**
   - Revisa manualmente algunos art√≠culos
   - Ajusta keywords si hay demasiados falsos positivos

4. **Almacenamiento**
   - Los JSON pueden ser grandes, considera comprimir archivos antiguos
   - Implementa rotaci√≥n de archivos para uso continuo

## üõ†Ô∏è Soluci√≥n de Problemas

### Error: "Request timeout"
- **Causa**: Fuente lenta o inaccesible
- **Soluci√≥n**: El scraper contin√∫a autom√°ticamente con la siguiente fuente

### Pocos resultados encontrados
- **Causa**: Keywords muy espec√≠ficas o art√≠culos recientes no disponibles
- **Soluci√≥n**: Ampl√≠a las keywords o ejecuta sin filtro

### "No se encontraron art√≠culos"
- **Causa**: Cambio en estructura HTML del sitio
- **Soluci√≥n**: El scraper usa selectores gen√©ricos, pero algunos sitios pueden requerir ajustes manuales

## üìù Notas Importantes

- ‚ö†Ô∏è **Uso √âtico**: Este scraper es para uso educativo y de investigaci√≥n
- ‚ö†Ô∏è **Respeta robots.txt**: Verifica que los sitios permitan scraping
- ‚ö†Ô∏è **Rate Limiting**: No sobrecargues los servidores
- ‚ö†Ô∏è **T√©rminos de Servicio**: Revisa los ToS de cada sitio

## üîÑ Actualizaci√≥n de Dependencias

```bash
pip install --upgrade -r requirements.txt
```

## üìÑ Licencia

Uso educativo y personal.

---

**Desarrollado para consultar noticias de tecnolog√≠a, IA y actualidad de m√∫ltiples fuentes especializadas.**
